{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single file csv processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "banksdirectory = r'C:\\Projects\\Finances\\Bank statements'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved au_consolidated_pd_2024-05-19.parquet to backup directory\n",
      "Moved hdfc_consolidated_pd_2024-05-19.parquet to backup directory\n",
      "Moved sbi_consolidated_pd_2024-05-19.parquet to backup directory\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "def hdfc_processing(hdfcdf):\n",
    "    # Convert each column to numeric\n",
    "    for column in columns_to_convert_to_numeric:\n",
    "        hdfcdf[column] = pd.to_numeric(hdfcdf[column], errors= 'coerce')\n",
    "    #check for NAN values\n",
    "    df['Debit'] = df['Debit'].fillna(0.0)\n",
    "    df['Credit'] = df['Credit'].fillna(0.0)\n",
    "    total_nan_count = hdfcdf['Credit'].isna().sum() + hdfcdf['Debit'].isna().sum() + hdfcdf['Balance'].isna().sum()\n",
    "    if total_nan_count > 0 :\n",
    "        raise Exception(\"Issue with value processing! Check for NaN values in 'Credit', 'Debit', or 'Balance' columns.\")\n",
    "    #Convert Date Colunmn to date format\n",
    "    hdfcdf['Date'] = pd.to_datetime(hdfcdf['Date'], format='%d/%m/%y')\n",
    "    \n",
    "    return hdfcdf\n",
    "\n",
    "\n",
    "def au_processing(audf):\n",
    "    #Convert Date Colunmn to date format\n",
    "    audf['Date'] = pd.to_datetime(audf['Date'], format='%d-%b-%y')\n",
    "\n",
    "    audf['Credit'] = audf['Credit'].str.replace('-','0')\n",
    "    audf['Debit'] = audf['Debit'].str.replace('-','0')\n",
    "\n",
    "    # Convert each column to numeric\n",
    "    for column in columns_to_convert_to_numeric:\n",
    "        audf[column] = pd.to_numeric(audf[column], errors= 'coerce')\n",
    "\n",
    "    #check for NAN values\n",
    "    total_nan_count = audf['Credit'].isna().sum() + audf['Debit'].isna().sum() + audf['Balance'].isna().sum()\n",
    "\n",
    "    if total_nan_count > 0 :\n",
    "        raise Exception(\"Issue with value processing! Check for NaN values in 'Credit', 'Debit', or 'Balance' columns.\")\n",
    "    \n",
    "    return audf\n",
    "\n",
    "def sbi_csv_processing(sbidf):\n",
    "    total_numeric_na_count = 0\n",
    "    # Date conversion\n",
    "    sbidf['Date'] = pd.to_datetime(sbidf['Date'],format=\"%d-%b-%y\", errors='coerce', dayfirst=True)\n",
    "    date_na_count = sbidf['Date'].isna().sum()\n",
    "\n",
    "    \n",
    "    for column in columns_to_convert_to_numeric:\n",
    "        sbidf[column] = sbidf[column].str.replace(\",\",\"\")\n",
    "        #df[column] = df[column].str.replace(\"\",\"0\")   this will add values cannot be done\n",
    "        sbidf[column] = pd.to_numeric(sbidf[column],errors='coerce')\n",
    "        if column == 'Balance':\n",
    "            pass\n",
    "        else:\n",
    "            # Identify rows where conversion resulted in NaN\n",
    "            sbidf.loc[:, column] = sbidf[column].fillna(0.0)\n",
    "        nacount = pd.to_numeric(sbidf[column],errors='coerce').isna().sum()\n",
    "        total_numeric_na_count += nacount\n",
    "\n",
    "    if total_numeric_na_count > 0 or date_na_count > 0 :\n",
    "        raise Exception(f\"error in prossesing {file_path} !!!! \\n NaN count breached limit.\\n \\\n",
    "                        Total na count = numeric : {total_numeric_na_count} \\n \\\n",
    "                                        date : {date_na_count}\\\n",
    "                        \")\n",
    "    \n",
    "    return sbidf \n",
    "\n",
    "def file_backup(banksdirectory):\n",
    "    # backup dir and create directory if not exists\n",
    "    backup_dir = os.path.join (banksdirectory,'backup_parquets')\n",
    "    os.makedirs(backup_dir , exist_ok= True)\n",
    "\n",
    "    # Find parquet files\n",
    "    files = [file for file in os.listdir(banksdirectory) if file.endswith(\".parquet\")]\n",
    "\n",
    "    # Move files\n",
    "    for file in files:\n",
    "        source = os.path.join(banksdirectory, file)\n",
    "        destination = os.path.join(backup_dir, file)\n",
    "        shutil.move(source, destination)\n",
    "        print(f\"Moved {file} to backup directory\")\n",
    "\n",
    "\n",
    "# Get today's date\n",
    "today_date = datetime.today()\n",
    "\n",
    "# Convert the date to a string in the format \"YYYY-MM-DD\"\n",
    "today_date_str = today_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "banksdirectory = r'C:\\Projects\\Finances\\Bank statements'\n",
    "directories = [\n",
    "        entry for entry in os.listdir(banksdirectory)\n",
    "        if os.path.isdir(os.path.join(banksdirectory, entry))\n",
    "        and entry not in banksdirectory\n",
    "        and entry != 'backup_parquets'\n",
    "    ]\n",
    "# Move files to bkp directory\n",
    "file_backup(banksdirectory)\n",
    "\n",
    "combined_dfs = {}\n",
    "for folder in directories: \n",
    "    files = [\n",
    "            file for file in os.listdir(os.path.join(banksdirectory, folder))\n",
    "            if file.endswith(\".csv\") or file.endswith(\".csv\")\n",
    "        ]\n",
    "    \n",
    "    column_order = ['Date', 'Description', 'Debit', 'Credit', 'Balance'] #'Value_date',  'Ref_No', \n",
    "\n",
    "    global columns_to_convert_to_numeric\n",
    "    # List of column names to convert to numeric\n",
    "    columns_to_convert_to_numeric = ['Debit', 'Credit', 'Balance']\n",
    "\n",
    "\n",
    "    # Create an empty DataFrame with specified column names\n",
    "    combined_dfs[f'{folder}_combined_df'] = pd.DataFrame(columns=column_order)\n",
    "    ####  f'{folder}_combined_df' = pd.DataFrame(columns=column_order)\n",
    "    dfs = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(os.path.join(banksdirectory, folder,file))\n",
    "\n",
    "        try:\n",
    "\n",
    "            df = pd.read_csv(file_path, header=0, dtype =str)\n",
    "            df = df[column_order]\n",
    "            # Remove leading and trailing whitespace from all string columns\n",
    "            for column in df.select_dtypes(include=['object']).columns:\n",
    "                    df[column] = df[column].str.strip()\n",
    "            #print(f\"file {file_path}: \\n {df[pd.to_datetime(df['Date'],format=\"%d-%b-%y\", errors='coerce', dayfirst=True).isna()]}\")\n",
    "            if folder == 'sbi':\n",
    "                df = sbi_csv_processing(df)\n",
    "            \n",
    "            if folder == 'hdfc':\n",
    "                df = hdfc_processing(df)\n",
    "            \n",
    "            if folder == 'au':\n",
    "                df = au_processing(df)\n",
    "            #appending to dfs list\n",
    "            dfs.append(df) \n",
    "\n",
    "        # combined_df = pd.concat([combined_df,df], ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (f'error occured in {file_path} :: \\n {str(e)}')\n",
    "            \n",
    "# Concatenate DataFrames and store the result back in the dictionary\n",
    "    try :\n",
    "        combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    except Exception as e:\n",
    "        print(f'Failed to create to df ::: \\n Folder :\\t {folder} \\n {str(e)}')\n",
    "\n",
    "    output_file_path = f\"{banksdirectory}/{folder}_consolidated_pd_{today_date_str}.parquet\"\n",
    "\n",
    "# Write the DataFrame to a Parquet file with the specified file name\n",
    "    try: \n",
    "        combined_df.to_parquet(output_file_path)\n",
    "        print(f'\\n Parquet written ::: {folder} \\n')\n",
    "    except Exception as e:\n",
    "        print(f'Failed to write to parquet ::: {output_file_path} \\n {str(e)}')\n",
    "\n",
    "\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Failure checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = r'C:\\Projects\\Finances\\Bank statements\\hdfc\\hdfc 01-Apr-2024 To 18-May-2024.csv'\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert each column to numeric\n",
    "for column in columns_to_convert_to_numeric:\n",
    "    df[column] = pd.to_numeric(df[column], errors= 'coerce')\n",
    "#check for NAN values\n",
    "total_nan_count = df['Credit'].isna().sum() + df['Debit'].isna().sum() + df['Balance'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Amirul\\AppData\\Local\\Temp\\ipykernel_19644\\2501405000.py:1: FutureWarning: DataFrame.replace without 'value' and with non-dict-like 'to_replace' is deprecated and will raise in a future version. Explicitly specify the new values instead.\n",
      "  df.isnull().replace('0.0')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Value_date</th>\n",
       "      <th>Ref_No</th>\n",
       "      <th>Debit</th>\n",
       "      <th>Credit</th>\n",
       "      <th>Balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Date  Description  Value_date  Ref_No  Debit  Credit  Balance\n",
       "0    False        False       False   False  False    True    False\n",
       "1    False        False       False   False   True   False    False\n",
       "2    False        False       False   False  False    True    False\n",
       "3    False        False       False   False  False    True    False\n",
       "4    False        False       False   False  False    True    False\n",
       "..     ...          ...         ...     ...    ...     ...      ...\n",
       "122  False        False       False   False  False    True    False\n",
       "123  False        False       False   False  False    True    False\n",
       "124  False        False       False   False  False    True    False\n",
       "125  False        False       False   False  False    True    False\n",
       "126  False        False       False   False  False    True    False\n",
       "\n",
       "[127 rows x 7 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Debit'].isnull().replace('0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Issue with value processing! Check for NaN values in 'Credit', 'Debit', or 'Balance' columns.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m\u001b[43mhdfc_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[38], line 14\u001b[0m, in \u001b[0;36mhdfc_processing\u001b[1;34m(hdfcdf)\u001b[0m\n\u001b[0;32m     12\u001b[0m total_nan_count \u001b[38;5;241m=\u001b[39m hdfcdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m hdfcdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDebit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m+\u001b[39m hdfcdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total_nan_count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIssue with value processing! Check for NaN values in \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCredit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDebit\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalance\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m columns.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m#Convert Date Colunmn to date format\u001b[39;00m\n\u001b[0;32m     16\u001b[0m hdfcdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(hdfcdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm/\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: Issue with value processing! Check for NaN values in 'Credit', 'Debit', or 'Balance' columns."
     ]
    }
   ],
   "source": [
    "df =hdfc_processing(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SBI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using consolidated parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "banksdirectory = r'C:\\Projects\\Finances\\Bank statements'\n",
    "files = [ file for file in os.listdir(banksdirectory) if file.endswith(\".parquet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "audf = pd.read_parquet(os.path.join(banksdirectory,files[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbidf = pd.read_parquet(os.path.join(banksdirectory,files[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDFC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfcdf = pd.read_parquet(os.path.join(banksdirectory,files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "db_path = r'C:\\Projects\\Finances\\database\\Transactions.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load_to_db(df,bank_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # Retrieve existing data from the \"transactions\" table\n",
    "    #existing_data = pd.read_sql_query(\"SELECT * FROM sbi_bank\", conn)\n",
    "    # Truncate the \"target\" table\n",
    "    conn.execute(f\"DELETE FROM {bank_name}_bank\")\n",
    "\n",
    "    # Insert new data into the \"sbi_target\" table\n",
    "    df.to_sql(f'{bank_name}_bank', conn, if_exists='replace', index=False)\n",
    "    # Commit changes and close connection\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load_to_db(sbidf,\"sbi\")\n",
    "data_load_to_db(hdfcdf,\"hdfc\")\n",
    "data_load_to_db(audf,\"au\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Date table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "minimun_date = pd.read_sql_query(\"SELECT min(date) FROM sbi_bank\", conn)\n",
    "# start date\n",
    "min_date = minimun_date['min(date)'][0]\n",
    "# end date\n",
    "end_date = pd.Timestamp('2030-12-31')\n",
    "\n",
    "# Generate a date range DataFrame\n",
    "dates = pd.date_range(start=minimun_date , end=end_date , freq=\"D\")\n",
    "\n",
    "# Extract date attributes\n",
    "\n",
    "date_df = pd.DataFrame (data=dates, columns=['Date'])\n",
    "\n",
    "date_df['Day'] = date_df['Date'].dt.day\n",
    "date_df['Month'] = date_df['Date'].dt.month\n",
    "date_df['Year'] = date_df['Date'].dt.year\n",
    "\n",
    "# Determine Indian financial year\n",
    "def indian_fy(date):\n",
    "    fy = date.year if date.month >=4 else date.year - 1\n",
    "    return 'FY '+ str(fy) + ' - ' + str(fy+1)\n",
    "date_df['Financial_Year'] = date_df['Date'].apply(indian_fy)\n",
    "#truncate current date table\n",
    "conn.execute(\"DELETE FROM date_table\") \n",
    "# Upload the date table to the database\n",
    "date_df.to_sql('date_table', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Automate updating (append new values)\n",
    "# Example:\n",
    "# new_dates_query = \"SELECT DISTINCT Date FROM sbi_bank WHERE Date > (SELECT max(Date) FROM date_table)\"\n",
    "# new_dates = pd.read_sql_query(new_dates_query, conn)\n",
    "# new_dates.to_sql('date_table', conn, if_exists='append', index=False)\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              datetime64[ns]\n",
       "Day                        int32\n",
       "Month                      int32\n",
       "Year                       int32\n",
       "Financial_Year            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.dtypes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
