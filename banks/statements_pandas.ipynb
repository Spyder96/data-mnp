{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single file csv processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "banksdirectory = r'C:\\Projects\\Finances\\Bank statements'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "def hdfc_processing(hdfcdf):\n",
    "    # Convert each column to numeric\n",
    "    for column in columns_to_convert_to_numeric:\n",
    "        hdfcdf[column] = pd.to_numeric(hdfcdf[column], errors= 'coerce')\n",
    "    #check for NAN values\n",
    "    total_nan_count = hdfcdf['Credit'].isna().sum() + hdfcdf['Debit'].isna().sum() + hdfcdf['Balance'].isna().sum()\n",
    "    if total_nan_count > 0 :\n",
    "        raise Exception(\"Issue with value processing! Check for NaN values in 'Credit', 'Debit', or 'Balance' columns.\")\n",
    "    #Convert Date Colunmn to date format\n",
    "    hdfcdf['Date'] = pd.to_datetime(hdfcdf['Date'], format='%d/%m/%y')\n",
    "    \n",
    "    return hdfcdf\n",
    "\n",
    "\n",
    "def au_processing(audf):\n",
    "    #Convert Date Colunmn to date format\n",
    "    audf['Date'] = pd.to_datetime(audf['Date'], format='%d-%b-%y')\n",
    "\n",
    "    audf['Credit'] = audf['Credit'].str.replace('-','0')\n",
    "    audf['Debit'] = audf['Debit'].str.replace('-','0')\n",
    "\n",
    "    # Convert each column to numeric\n",
    "    for column in columns_to_convert_to_numeric:\n",
    "        audf[column] = pd.to_numeric(audf[column], errors= 'coerce')\n",
    "\n",
    "    #check for NAN values\n",
    "    total_nan_count = audf['Credit'].isna().sum() + audf['Debit'].isna().sum() + audf['Balance'].isna().sum()\n",
    "\n",
    "    if total_nan_count > 0 :\n",
    "        raise Exception(\"Issue with value processing! Check for NaN values in 'Credit', 'Debit', or 'Balance' columns.\")\n",
    "    \n",
    "    return audf\n",
    "\n",
    "def sbi_csv_processing(sbidf):\n",
    "    total_numeric_na_count = 0\n",
    "    # Date conversion\n",
    "    sbidf['Date'] = pd.to_datetime(sbidf['Date'],format=\"%d-%b-%y\", errors='coerce', dayfirst=True)\n",
    "    date_na_count = sbidf['Date'].isna().sum()\n",
    "\n",
    "    \n",
    "    for column in columns_to_convert_to_numeric:\n",
    "        sbidf[column] = sbidf[column].str.replace(\",\",\"\")\n",
    "        #df[column] = df[column].str.replace(\"\",\"0\")   this will add values cannot be done\n",
    "        sbidf[column] = pd.to_numeric(sbidf[column],errors='coerce')\n",
    "        if column == 'Balance':\n",
    "            pass\n",
    "        else:\n",
    "            # Identify rows where conversion resulted in NaN\n",
    "            sbidf.loc[:, column] = sbidf[column].fillna(0.0)\n",
    "        nacount = pd.to_numeric(sbidf[column],errors='coerce').isna().sum()\n",
    "        total_numeric_na_count += nacount\n",
    "\n",
    "    if total_numeric_na_count > 0 or date_na_count > 0 :\n",
    "        raise Exception(f\"error in prossesing {file_path} !!!! \\n NaN count breached limit.\\n \\\n",
    "                        Total na count = numeric : {total_numeric_na_count} \\n \\\n",
    "                                        date : {date_na_count}\\\n",
    "                        \")\n",
    "    \n",
    "    return sbidf \n",
    "    \n",
    "# Get today's date\n",
    "today_date = datetime.today()\n",
    "\n",
    "# Convert the date to a string in the format \"YYYY-MM-DD\"\n",
    "today_date_str = today_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "banksdirectory = r'C:\\Projects\\Finances\\Bank statements'\n",
    "directories = [\n",
    "        entry for entry in os.listdir(banksdirectory)\n",
    "        if os.path.isdir(os.path.join(banksdirectory, entry))\n",
    "        and entry not in banksdirectory\n",
    "    ]\n",
    "\n",
    "combined_dfs = {}\n",
    "for folder in directories: \n",
    "    files = [\n",
    "            file for file in os.listdir(os.path.join(banksdirectory, folder))\n",
    "            if file.endswith(\".csv\") or file.endswith(\".csv\")\n",
    "        ]\n",
    "    \n",
    "    column_order = ['Date', 'Description', 'Debit', 'Credit', 'Balance'] #'Value_date',  'Ref_No', \n",
    "\n",
    "    global columns_to_convert_to_numeric\n",
    "    # List of column names to convert to numeric\n",
    "    columns_to_convert_to_numeric = ['Debit', 'Credit', 'Balance']\n",
    "\n",
    "\n",
    "    # Create an empty DataFrame with specified column names\n",
    "    combined_dfs[f'{folder}_combined_df'] = pd.DataFrame(columns=column_order)\n",
    "    ####  f'{folder}_combined_df' = pd.DataFrame(columns=column_order)\n",
    "    dfs = []\n",
    "\n",
    "    for file in files:\n",
    "        file_path = os.path.join(os.path.join(banksdirectory, folder,file))\n",
    "\n",
    "        try:\n",
    "\n",
    "            df = pd.read_csv(file_path, header=0, dtype =str)\n",
    "            df = df[column_order]\n",
    "            # Remove leading and trailing whitespace from all string columns\n",
    "            for column in df.select_dtypes(include=['object']).columns:\n",
    "                    df[column] = df[column].str.strip()\n",
    "            #print(f\"file {file_path}: \\n {df[pd.to_datetime(df['Date'],format=\"%d-%b-%y\", errors='coerce', dayfirst=True).isna()]}\")\n",
    "            if folder == 'sbi':\n",
    "                df = sbi_csv_processing(df)\n",
    "            \n",
    "            if folder == 'hdfc':\n",
    "                df = hdfc_processing(df)\n",
    "            \n",
    "            if folder == 'au':\n",
    "                df = au_processing(df)\n",
    "            #appending to dfs list\n",
    "            dfs.append(df) \n",
    "\n",
    "        # combined_df = pd.concat([combined_df,df], ignore_index=True)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print (f'error occured in {file_path} :: \\n {str(e)}')\n",
    "            \n",
    "# Concatenate DataFrames and store the result back in the dictionary\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    output_file_path = f\"{banksdirectory}/{folder}_consolidated_pd_{today_date_str}.parquet\"\n",
    "        # Write the DataFrame to a Parquet file with the specified file name\n",
    "    combined_df.to_parquet(output_file_path)\n",
    "\n",
    "\n",
    "#print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combined_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SBI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           0\n",
       "Description    0\n",
       "Debit          0\n",
       "Credit         0\n",
       "Balance        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dfs['sbi_combined_df'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           object\n",
       "Description    object\n",
       "Debit          object\n",
       "Credit         object\n",
       "Balance        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dfs['hdfc_combined_df'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           datetime64[ns]\n",
       "Description            object\n",
       "Debit                 float64\n",
       "Credit                float64\n",
       "Balance               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_dfs['sbi_combined_df'].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbidf = sbi_csv_processing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Debit'] = df['Debit'].str.replace(\",\",\"\")\n",
    "#df['Debit'] = df[column].str.replace(\"\",\"0\")\n",
    "df['Debit'] = pd.to_numeric(df['Debit'],errors='coerce')\n",
    "\n",
    "\n",
    "\n",
    "# Replace empty strings with NaN in rows where the conversion resulted in NaN\n",
    "#df.loc[nan_rows & (df['Debit'].astype(str) == ''), 'Date'] = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using consolidated parquet file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "banksdirectory = r'C:\\Projects\\Finances\\Bank statements'\n",
    "files = [ file for file in os.listdir(banksdirectory) if file.endswith(\".parquet\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['au_consolidated_2024-05-14.parquet',\n",
       " 'au_consolidated_pd_2024-05-15.parquet',\n",
       " 'hdfc_consolidated_2024-05-14.parquet',\n",
       " 'hdfc_consolidated_pd_2024-05-15.parquet',\n",
       " 'sbi_consolidated_2024-05-14.parquet',\n",
       " 'sbi_consolidated_pd_2024-05-15.parquet']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "audf = pd.read_parquet(os.path.join(banksdirectory,files[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           datetime64[ns]\n",
       "Description            object\n",
       "Debit                 float64\n",
       "Credit                float64\n",
       "Balance               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#audf = au_processing(audf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date           datetime64[ns]\n",
       "Description            object\n",
       "Debit                 float64\n",
       "Credit                float64\n",
       "Balance               float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### SBI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbidf = pd.read_parquet(os.path.join(banksdirectory,files[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sbidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDFC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdfcdf = pd.read_parquet(os.path.join(banksdirectory,files[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hdfcdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "from datetime import datetime\n",
    "db_path = r'C:\\Projects\\Finances\\database\\Transactions.db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_load_to_db(df,bank_name):\n",
    "    # Connect to the SQLite database\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    # Retrieve existing data from the \"transactions\" table\n",
    "    #existing_data = pd.read_sql_query(\"SELECT * FROM sbi_bank\", conn)\n",
    "    # Truncate the \"target\" table\n",
    "    conn.execute(f\"DELETE FROM {bank_name}_bank\")\n",
    "\n",
    "    # Insert new data into the \"sbi_target\" table\n",
    "    df.to_sql(f'{bank_name}_bank', conn, if_exists='replace', index=False)\n",
    "    # Commit changes and close connection\n",
    "    conn.commit()\n",
    "    conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_load_to_db(sbidf,\"sbi\")\n",
    "data_load_to_db(hdfcdf,\"hdfc\")\n",
    "data_load_to_db(audf,\"au\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(db_path)\n",
    "minimun_date = pd.read_sql_query(\"SELECT min(date) FROM sbi_bank\", conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min(date)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-04-01 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             min(date)\n",
       "0  2020-04-01 00:00:00"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimun_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_date = minimun_date['min(date)'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# end date\n",
    "end_date = pd.Timestamp('2030-12-31')\n",
    "\n",
    "# Generate a date range DataFrame\n",
    "dates = pd.date_range(start=min_date , end=end_date , freq=\"D\")\n",
    "\n",
    "# Extract date attributes\n",
    "\n",
    "date_df = pd.DataFrame (data=dates, columns=['Date'])\n",
    "\n",
    "date_df['Day'] = date_df['Date'].dt.day\n",
    "date_df['Month'] = date_df['Date'].dt.month\n",
    "date_df['Year'] = date_df['Date'].dt.year\n",
    "\n",
    "# Determine Indian financial year\n",
    "def indian_fy(date):\n",
    "    fy = date.year if date.month >=4 else date.year + 1\n",
    "    return 'FY '+ str(fy) + ' - ' + str(fy+1)\n",
    "date_df['Financial_Year'] = date_df['Date'].apply(indian_fy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the date table to the database\n",
    "date_df.to_sql('date_table', conn, if_exists='replace', index=False)\n",
    "\n",
    "# Automate updating (append new values)\n",
    "# Example:\n",
    "# new_dates_query = \"SELECT DISTINCT Date FROM sbi_bank WHERE Date > (SELECT max(Date) FROM date_table)\"\n",
    "# new_dates = pd.read_sql_query(new_dates_query, conn)\n",
    "# new_dates.to_sql('date_table', conn, if_exists='append', index=False)\n",
    "\n",
    "# Commit changes and close connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date              datetime64[ns]\n",
       "Day                        int32\n",
       "Month                      int32\n",
       "Year                       int32\n",
       "Financial_Year            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "date_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "portfolio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
